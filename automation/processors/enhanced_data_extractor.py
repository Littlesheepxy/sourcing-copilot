#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆæ•°æ®æå–å™¨
ä½¿ç”¨æ›´æ™ºèƒ½çš„ä¿¡æ¯æå–é€»è¾‘æ¥è§£æç®€å†æ•°æ®
"""

import re
import uuid
from typing import Dict, List, Optional, Any
from playwright.async_api import Page, ElementHandle


class EnhancedDataExtractor:
    """å¢å¼ºç‰ˆæ•°æ®æå–å™¨ï¼Œä½¿ç”¨æ›´æ™ºèƒ½çš„ä¿¡æ¯æå–é€»è¾‘"""
    
    def __init__(self):
        # æ•™è‚²å…³é”®è¯
        self.education_keywords = {
            'åšå£«': ['åšå£«', 'PhD', 'Ph.D', 'åšå£«ç ”ç©¶ç”Ÿ', 'åšå£«å­¦ä½'],
            'ç¡•å£«': ['ç¡•å£«', 'ç ”ç©¶ç”Ÿ', 'Master', 'M.A', 'M.S', 'MBA', 'ç¡•å£«ç ”ç©¶ç”Ÿ', 'ç¡•å£«å­¦ä½'],
            'æœ¬ç§‘': ['æœ¬ç§‘', 'å­¦å£«', 'Bachelor', 'B.A', 'B.S', 'å¤§å­¦æœ¬ç§‘', 'å­¦å£«å­¦ä½'],
            'å¤§ä¸“': ['å¤§ä¸“', 'ä¸“ç§‘', 'é«˜èŒ', 'å¤§å­¦ä¸“ç§‘'],
            'é«˜ä¸­': ['é«˜ä¸­', 'ä¸­ä¸“', 'æŠ€æ ¡', 'èŒé«˜']
        }
        
        # èŒä½å…³é”®è¯
        self.position_keywords = [
            'å·¥ç¨‹å¸ˆ', 'å¼€å‘', 'ç¨‹åºå‘˜', 'æ¶æ„å¸ˆ', 'æŠ€æœ¯', 'ç»ç†', 'ä¸»ç®¡', 'æ€»ç›‘', 
            'ä¸“å‘˜', 'åŠ©ç†', 'é¡¾é—®', 'åˆ†æå¸ˆ', 'è®¾è®¡å¸ˆ', 'äº§å“', 'è¿è¥', 'å¸‚åœº',
            'é”€å”®', 'å®¢æœ', 'äººäº‹', 'è´¢åŠ¡', 'æ³•åŠ¡', 'ç­–åˆ’', 'ç¼–è¾‘', 'æµ‹è¯•'
        ]
        
        # å…¬å¸åç¼€
        self.company_suffixes = [
            'æœ‰é™å…¬å¸', 'è‚¡ä»½æœ‰é™å…¬å¸', 'é›†å›¢', 'ç§‘æŠ€', 'æŠ€æœ¯', 'ä¿¡æ¯', 'ç½‘ç»œ',
            'è½¯ä»¶', 'ç”µå­', 'é€šä¿¡', 'äº’è”ç½‘', 'é‡‘è', 'æŠ•èµ„', 'å’¨è¯¢', 'æœåŠ¡'
        ]
        
        # æŠ€èƒ½å…³é”®è¯åº“
        self.skill_keywords = {
            'ç¼–ç¨‹è¯­è¨€': ['Java', 'Python', 'C++', 'C#', 'JavaScript', 'TypeScript', 'Go', 'Rust', 'Swift', 'Kotlin'],
            'å‰ç«¯æŠ€æœ¯': ['React', 'Vue', 'Angular', 'HTML', 'CSS', 'jQuery', 'Bootstrap', 'Webpack'],
            'åç«¯æŠ€æœ¯': ['Spring', 'Django', 'Flask', 'Express', 'Node.js', 'Laravel', 'Rails'],
            'æ•°æ®åº“': ['MySQL', 'PostgreSQL', 'MongoDB', 'Redis', 'Oracle', 'SQL Server', 'SQLite'],
            'äº‘æœåŠ¡': ['AWS', 'Azure', 'GCP', 'Docker', 'Kubernetes', 'å¾®æœåŠ¡', 'åˆ†å¸ƒå¼'],
            'å·¥å…·': ['Git', 'Jenkins', 'Maven', 'Gradle', 'npm', 'yarn', 'Linux', 'Windows']
        }

    async def extract_resume_data(self, page: Page, card_selector: str = None, selectors: dict = None) -> Dict[str, Any]:
        """
        å¢å¼ºçš„ç®€å†æ•°æ®æå–å™¨
        ä½¿ç”¨å¤šç§ç­–ç•¥æå–ç®€å†ä¿¡æ¯
        """
        data = {}
        
        try:
            # è·å–é¡µé¢å®Œæ•´æ–‡æœ¬ - ä¿®å¤ï¼šæ·»åŠ é€‰æ‹©å™¨å‚æ•°
            # å…ˆå°è¯•è·å–å¼¹çª—å†…å®¹ï¼Œå¦‚æœæ²¡æœ‰åˆ™è·å–æ•´ä¸ªé¡µé¢
            full_text = None
            
            # ä¼˜å…ˆå°è¯•è·å–BOSSç›´è˜å¼¹çª—å†…å®¹ - æŒ‰ä¼˜å…ˆçº§æ’åº
            selectors_to_try = [
                '.resume-detail-wrap',           # ç®€å†è¯¦æƒ…ä¸»å®¹å™¨
                '.dialog-wrap.active',           # æ´»åŠ¨çš„å¼¹çª—
                '.boss-dialog__body',            # å¼¹çª—ä¸»ä½“
                '.lib-resume-recommend',         # ç®€å†æ¨èå®¹å™¨
                '#boss-dynamic-dialog-1it1ej9u8', # ç‰¹å®šçš„å¼¹çª—IDï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                '.dialog-wrap',                  # é€šç”¨å¼¹çª—
                'body'                           # æœ€åå°è¯•æ•´ä¸ªé¡µé¢
            ]
            
            for selector in selectors_to_try:
                try:
                    full_text = await page.text_content(selector)
                    if full_text and len(full_text.strip()) > 100:  # ç¡®ä¿è·å–åˆ°äº†è¶³å¤Ÿçš„å†…å®¹
                        print(f"âœ… æˆåŠŸä½¿ç”¨é€‰æ‹©å™¨è·å–å†…å®¹: {selector}")
                        break
                except Exception as e:
                    print(f"âŒ é€‰æ‹©å™¨ {selector} å¤±è´¥: {str(e)}")
                    continue
            
            if not full_text:
                print("âŒ æ— æ³•è·å–é¡µé¢æ–‡æœ¬å†…å®¹")
                return data
                
            # æ¸…ç†æ–‡æœ¬
            cleaned_text = self._clean_text(full_text)
            data['fullText'] = cleaned_text
            
            # å…ˆå°è¯•ä½¿ç”¨DOMé€‰æ‹©å™¨ç²¾ç¡®æå–ä¿¡æ¯ï¼ˆå¦‚æœåœ¨å¡ç‰‡é¡µé¢ï¼‰
            try:
                if card_selector or await page.query_selector('.candidate-card-wrap, .card-inner'):
                    print("ğŸ¯ æ£€æµ‹åˆ°å¡ç‰‡é¡µé¢ï¼Œä½¿ç”¨ç²¾ç¡®DOMé€‰æ‹©å™¨æå–...")
                    dom_data = await self._extract_from_dom(page, card_selector)
                    if dom_data:
                        data.update(dom_data)
                        print(f"âœ… DOMæå–æˆåŠŸ: å§“å={data.get('name')}, èŒä½={data.get('position')}")
            except Exception as e:
                print(f"âš ï¸ DOMæå–å¤±è´¥ï¼Œå›é€€åˆ°æ–‡æœ¬æå–: {e}")
            
            # å¦‚æœDOMæå–å¤±è´¥æˆ–ä¸å®Œæ•´ï¼Œä½¿ç”¨æ–‡æœ¬æå–ä½œä¸ºè¡¥å……
            if not data.get('name') or not data.get('position'):
                print("ğŸ”„ ä½¿ç”¨æ–‡æœ¬æå–è¡¥å……ä¿¡æ¯...")
                text_data = self._extract_from_text(cleaned_text)
                # åªè¡¥å……ç¼ºå¤±çš„å­—æ®µ
                for key, value in text_data.items():
                    if not data.get(key) and value:
                        data[key] = value
            
            # Bossç›´è˜ç‰¹æœ‰ä¿¡æ¯æå–
            if not data.get('salary_expectation'):
                data['salary_expectation'] = self._extract_salary_expectation(cleaned_text)
            if not data.get('work_location'):
                data['work_location'] = self._extract_work_location(cleaned_text)
            if not data.get('position_experience'):
                data['position_experience'] = self._extract_position_experience(cleaned_text)
            
            print(f"âœ… å¢å¼ºæå–å®Œæˆ: å§“å={data.get('name')}, å­¦å†={data.get('education')}, èŒä½={data.get('position')}, æœŸæœ›è–ªèµ„={data.get('salary_expectation')}")
            
        except Exception as e:
            print(f"âŒ å¢å¼ºæ•°æ®æå–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
        return data

    async def _extract_from_dom(self, page: Page, card_selector: str = None) -> Dict[str, Any]:
        """
        ä½¿ç”¨DOMé€‰æ‹©å™¨ç²¾ç¡®æå–ä¿¡æ¯
        
        Args:
            page: Playwrighté¡µé¢å¯¹è±¡
            card_selector: å¡ç‰‡é€‰æ‹©å™¨
            
        Returns:
            Dict[str, Any]: æå–çš„æ•°æ®
        """
        data = {}
        
        try:
            # ç¡®å®šå®¹å™¨é€‰æ‹©å™¨
            container_selector = card_selector if card_selector else '.candidate-card-wrap, .card-inner, .resume-detail-wrap'
            
            # æå–å§“å - ä½¿ç”¨æ›´ç²¾ç¡®çš„é€‰æ‹©å™¨
            name_selectors = [
                '.name',                           # é€šç”¨å§“åé€‰æ‹©å™¨
                '.row.name-wrap .name',           # å¡ç‰‡ä¸­çš„å§“å
                '.geek-base-info-wrap .name',     # è¯¦æƒ…é¡µä¸­çš„å§“å
                '[class*="name"]'                 # åŒ…å«nameçš„ç±»å
            ]
            
            for name_sel in name_selectors:
                try:
                    full_selector = f"{container_selector} {name_sel}" if container_selector != 'body' else name_sel
                    name_element = await page.query_selector(full_selector)
                    if name_element:
                        name = await name_element.text_content()
                        if name and name.strip() and name.strip() not in ['é¢è®®', 'ä¿å¯†', 'æš‚æ— ', '']:
                            data['name'] = name.strip()
                            print(f"âœ… DOMæå–å§“å: {data['name']} (é€‰æ‹©å™¨: {full_selector})")
                            break
                except Exception as e:
                    print(f"âš ï¸ å§“åé€‰æ‹©å™¨ {name_sel} å¤±è´¥: {e}")
                    continue
            
            # æå–æœŸæœ›èŒä½
            position_selectors = [
                '.content .join-text-wrap',       # æœŸæœ›èŒä½å†…å®¹
                '.geek-expect-wrap .join-text-wrap', # è¯¦æƒ…é¡µæœŸæœ›èŒä½
                '[class*="expect"] .content',     # æœŸæœ›ç›¸å…³å†…å®¹
                '.row-flex .content'              # è¡Œå†…å®¹
            ]
            
            for pos_sel in position_selectors:
                try:
                    full_selector = f"{container_selector} {pos_sel}" if container_selector != 'body' else pos_sel
                    position_elements = await page.query_selector_all(full_selector)
                    for element in position_elements:
                        position_text = await element.text_content()
                        if position_text and 'æœŸæœ›' in await page.text_content(f"{full_selector}//ancestor::*[contains(@class, 'row')]"):
                            # ä»æœŸæœ›èŒä½æ–‡æœ¬ä¸­æå–èŒä½
                            position = self._extract_position_from_text(position_text.strip())
                            if position:
                                data['position'] = position
                                print(f"âœ… DOMæå–èŒä½: {data['position']}")
                                break
                except Exception as e:
                    continue
                
                if data.get('position'):
                    break
            
            # æå–å­¦å†
            education_selectors = [
                '.base-info',                     # åŸºæœ¬ä¿¡æ¯
                '.join-text-wrap',               # è¿æ¥æ–‡æœ¬
                '.geek-base-info-wrap'           # è¯¦æƒ…é¡µåŸºæœ¬ä¿¡æ¯
            ]
            
            for edu_sel in education_selectors:
                try:
                    full_selector = f"{container_selector} {edu_sel}" if container_selector != 'body' else edu_sel
                    edu_elements = await page.query_selector_all(full_selector)
                    for element in edu_elements:
                        edu_text = await element.text_content()
                        if edu_text:
                            education = self._extract_education_from_text(edu_text)
                            if education:
                                data['education'] = education
                                print(f"âœ… DOMæå–å­¦å†: {data['education']}")
                                break
                except Exception as e:
                    continue
                    
                if data.get('education'):
                    break
            
            # æå–å…¬å¸ä¿¡æ¯
            company_selectors = [
                '.timeline-wrap.work-exps .content',  # å·¥ä½œç»å†å†…å®¹
                '.work-exp-box .company',             # å·¥ä½œç»å†å…¬å¸
                '.timeline-item .content'             # æ—¶é—´è½´å†…å®¹
            ]
            
            companies = []
            for comp_sel in company_selectors:
                try:
                    full_selector = f"{container_selector} {comp_sel}" if container_selector != 'body' else comp_sel
                    comp_elements = await page.query_selector_all(full_selector)
                    for element in comp_elements:
                        comp_text = await element.text_content()
                        if comp_text:
                            company = self._extract_company_from_text(comp_text)
                            if company and company not in companies and company != 'ä¿å¯†':
                                companies.append(company)
                except Exception as e:
                    continue
            
            if companies:
                data['company'] = companies
                print(f"âœ… DOMæå–å…¬å¸: {companies}")
            
            # æå–å­¦æ ¡ä¿¡æ¯
            school_selectors = [
                '.timeline-wrap.edu-exps .content',   # æ•™è‚²ç»å†å†…å®¹
                '.edu-exp-box .school',               # æ•™è‚²ç»å†å­¦æ ¡
                '.education .content'                 # æ•™è‚²å†…å®¹
            ]
            
            schools = []
            for school_sel in school_selectors:
                try:
                    full_selector = f"{container_selector} {school_sel}" if container_selector != 'body' else school_sel
                    school_elements = await page.query_selector_all(full_selector)
                    for element in school_elements:
                        school_text = await element.text_content()
                        if school_text:
                            school = self._extract_school_from_text(school_text)
                            if school and school not in schools:
                                schools.append(school)
                except Exception as e:
                    continue
            
            if schools:
                data['schools'] = schools
                print(f"âœ… DOMæå–å­¦æ ¡: {schools}")
            
            # æå–æŠ€èƒ½æ ‡ç­¾
            skill_selectors = [
                '.tags-wrap .tag-item',              # æŠ€èƒ½æ ‡ç­¾
                '.tag-list .tag',                    # æ ‡ç­¾åˆ—è¡¨
                '.skill-tag'                         # æŠ€èƒ½æ ‡ç­¾
            ]
            
            skills = []
            for skill_sel in skill_selectors:
                try:
                    full_selector = f"{container_selector} {skill_sel}" if container_selector != 'body' else skill_sel
                    skill_elements = await page.query_selector_all(full_selector)
                    for element in skill_elements:
                        skill_text = await element.text_content()
                        if skill_text and skill_text.strip():
                            skill = skill_text.strip()
                            if skill not in skills and len(skill) < 20:
                                skills.append(skill)
                except Exception as e:
                    continue
            
            if skills:
                data['skills'] = skills
                print(f"âœ… DOMæå–æŠ€èƒ½: {skills}")
            
            return data
            
        except Exception as e:
            print(f"âŒ DOMæå–å¤±è´¥: {e}")
            return {}

    def _extract_from_text(self, text: str) -> Dict[str, Any]:
        """
        ä»æ–‡æœ¬ä¸­æå–ä¿¡æ¯ï¼ˆä½œä¸ºDOMæå–çš„å¤‡ç”¨æ–¹æ¡ˆï¼‰
        
        Args:
            text: æ¸…ç†åçš„æ–‡æœ¬
            
        Returns:
            Dict[str, Any]: æå–çš„æ•°æ®
        """
        data = {}
        
        # æå–å„ç§ä¿¡æ¯
        data['name'] = self._extract_name(text)
        data['education'] = self._extract_education(text)
        data['position'] = self._extract_position(text)
        data['company'] = self._extract_companies(text)
        data['schools'] = self._extract_schools(text)
        data['skills'] = self._extract_skills(text)
        data['experience'] = self._extract_experience(text)
        data['phone'] = self._extract_phone(text)
        data['email'] = self._extract_email(text)
        
        return data

    def _extract_position_from_text(self, text: str) -> str:
        """ä»æ–‡æœ¬ä¸­æå–èŒä½ä¿¡æ¯"""
        if not text:
            return ""
            
        # ç§»é™¤åœ°ç‚¹ä¿¡æ¯ï¼Œåªä¿ç•™èŒä½
        parts = text.split('â€¢')
        if len(parts) >= 2:
            position = parts[1].strip()
        else:
            # æŒ‰ç…§å…¶ä»–åˆ†éš”ç¬¦å°è¯•
            for sep in ['|', 'Â·', '-', ' ']:
                parts = text.split(sep)
                if len(parts) >= 2:
                    position = parts[1].strip()
                    break
            else:
                position = text.strip()
        
        return self._clean_position(position)

    def _extract_education_from_text(self, text: str) -> str:
        """ä»æ–‡æœ¬ä¸­æå–å­¦å†ä¿¡æ¯"""
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        education_order = ['åšå£«', 'ç¡•å£«', 'æœ¬ç§‘', 'å¤§ä¸“', 'é«˜ä¸­']
        
        for edu_level in education_order:
            if edu_level in text:
                return edu_level
                    
        return ""

    def _extract_school_from_text(self, text: str) -> str:
        """ä»æ–‡æœ¬ä¸­æå–å­¦æ ¡ä¿¡æ¯"""
        # æŸ¥æ‰¾åŒ…å«"å¤§å­¦"ã€"å­¦é™¢"ç­‰å…³é”®è¯çš„æ–‡æœ¬
        school_keywords = ['å¤§å­¦', 'å­¦é™¢', 'å­¦æ ¡', 'èŒä¸šæŠ€æœ¯å­¦é™¢', 'å¸ˆèŒƒ']
        for keyword in school_keywords:
            if keyword in text:
                # æå–åŒ…å«å…³é”®è¯çš„éƒ¨åˆ†
                parts = text.split('â€¢')
                for part in parts:
                    if keyword in part:
                        return self._clean_school_name(part.strip())
        
        return ""

    def _clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬"""
        if not text:
            return ""
            
        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        text = re.sub(r'\s+', ' ', text)
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œä½†ä¿ç•™+å·
        text = re.sub(r'[^\u4e00-\u9fff\w\s\.\-\(\)ï¼ˆï¼‰ï¼š:ï¼Œ,ã€‚\+]', ' ', text)
        return text.strip()

    def _extract_name(self, text: str) -> str:
        """æå–å§“å"""
        # BOSSç›´è˜ç‰¹å®šçš„å§“åæ¨¡å¼
        patterns = [
            r'å§“å[ï¼š:]\s*([^\s\n]{2,4})',
            r'å€™é€‰äºº[ï¼š:]\s*([^\s\n]{2,4})',
            r'ç®€å†[ï¼š:]\s*([^\s\n]{2,4})',
            r'è”ç³»äºº[ï¼š:]\s*([^\s\n]{2,4})',
            # æ–°å¢ï¼šä»é¡µé¢æ ‡é¢˜æˆ–å…¶ä»–ä½ç½®æå–å§“å
            r'ç‰›äºº[ï¼š:]\s*([^\s\n]{2,4})',
            r'æ±‚èŒè€…[ï¼š:]\s*([^\s\n]{2,4})',
        ]
        
        # éœ€è¦æ’é™¤çš„è¯æ±‡
        excluded_words = {'é¢è®®', 'ä¿å¯†', 'æš‚æ— ', 'æœ¬å‘¨', 'æ´»è·ƒ', 'åœ¨èŒ', 'è€ƒè™‘', 'æœºä¼š', 'å¹´ä»¥ä¸Š', 'ç¡•å£«', 'æœ¬ç§‘', 'å¤§ä¸“', 'åšå£«'}
        
        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                name = match.group(1).strip()
                # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆå§“åï¼ˆä¸­æ–‡2-4å­—ç¬¦ä¸”ä¸åœ¨æ’é™¤åˆ—è¡¨ä¸­ï¼‰
                if re.match(r'^[\u4e00-\u9fff]{2,4}$', name) and name not in excluded_words:
                    return name
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•æå–æ–‡æœ¬ä¸­çš„ä¸­æ–‡å§“å
        # å°†æ–‡æœ¬æŒ‰ç©ºæ ¼å’Œå¸¸è§åˆ†éš”ç¬¦åˆ†å‰²
        words = re.split(r'[\sï¼Œ,ã€‚ï¼›;ï¼!ï¼Ÿ?\n\r]+', text)
        
        for word in words:
            word = word.strip()
            # æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„ä¸­æ–‡å§“å
            if (re.match(r'^[\u4e00-\u9fff]{2,4}$', word) and 
                word not in excluded_words and
                not re.match(r'^\d+', word) and  # ä¸ä»¥æ•°å­—å¼€å¤´
                word not in ['æœŸæœ›', 'ä¼˜åŠ¿', 'æŠ€èƒ½', 'å·¥ä½œ', 'æ•™è‚²', 'é¡¹ç›®']):  # ä¸æ˜¯å¸¸è§æ ‡ç­¾
                return word
        
        # BOSSç›´è˜ä¸­ç»å¸¸æ²¡æœ‰æ˜¾ç¤ºå§“åï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
        return ""

    def _extract_education(self, text: str) -> str:
        """æå–å­¦å†"""
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        education_order = ['åšå£«', 'ç¡•å£«', 'æœ¬ç§‘', 'å¤§ä¸“', 'é«˜ä¸­']
        
        for edu_level in education_order:
            for keyword in self.education_keywords[edu_level]:
                if keyword in text:
                    return edu_level
                    
        return ""

    def _extract_position(self, text: str) -> str:
        """æå–æœŸæœ›èŒä½"""
        # BOSSç›´è˜ç‰¹å®šçš„æœŸæœ›èŒä½æ¨¡å¼
        patterns = [
            r'æœŸæœ›èŒä½[ï¼š:]\s*([^\n\r]{2,30})',
            r'æœŸæœ›å²—ä½[ï¼š:]\s*([^\n\r]{2,30})',
            r'åº”è˜èŒä½[ï¼š:]\s*([^\n\r]{2,30})',
            r'æœŸæœ›[ï¼š:]\s*([^\n\rï¼Œ,]{2,20})',
            # æ–°å¢ï¼šåŒ¹é…BOSSç›´è˜çš„æœŸæœ›èŒä½æ ¼å¼ï¼ˆåŸå¸‚ | èŒä½ | è¡Œä¸š | è–ªèµ„ï¼‰
            r'åŒ—äº¬[\s\|]*([^|\n\r]{2,15})[\s\|]*è¡Œä¸šä¸é™',
            r'ä¸Šæµ·[\s\|]*([^|\n\r]{2,15})[\s\|]*è¡Œä¸šä¸é™',
            r'å¹¿å·[\s\|]*([^|\n\r]{2,15})[\s\|]*è¡Œä¸šä¸é™',
            r'æ·±åœ³[\s\|]*([^|\n\r]{2,15})[\s\|]*è¡Œä¸šä¸é™',
            # åŒ¹é…èŒä½ + è–ªèµ„çš„æ ¼å¼
            r'([^|\n\r]{2,15})[\s\|]*\d+-\d+K',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                position = match.group(1).strip()
                # æ¸…ç†èŒä½ä¿¡æ¯
                position = self._clean_position(position)
                if position:
                    return position
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ç¡®çš„æœŸæœ›èŒä½ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æ‰¾èŒä½å…³é”®è¯
        for keyword in self.position_keywords:
            if keyword in text:
                # æŸ¥æ‰¾åŒ…å«è¯¥å…³é”®è¯çš„çŸ­è¯­
                pattern = rf'([^\s\n]{{0,10}}{re.escape(keyword)}[^\s\n]{{0,10}})'
                match = re.search(pattern, text)
                if match:
                    position = match.group(1).strip()
                    position = self._clean_position(position)
                    if position and len(position) < 20:
                        return position
                        
        return ""

    def _clean_position(self, position: str) -> str:
        """æ¸…ç†èŒä½ä¿¡æ¯"""
        if not position:
            return ""
            
        # ç§»é™¤æ˜æ˜¾ä¸æ˜¯èŒä½çš„ä¿¡æ¯
        invalid_patterns = [
            r'\d+å²', r'\d+å¹´', r'ç¦»èŒ', r'åœ¨èŒ', r'æœ¬ç§‘', r'å¤§ä¸“', r'ç¡•å£«', r'åšå£«',
            r'\d{4}\.\d{2}', r'ç»éªŒ', r'å·¥ä½œ', r'æ¯•ä¸š'
        ]
        
        for pattern in invalid_patterns:
            position = re.sub(pattern, '', position)
            
        # æ¸…ç†å¤šä½™çš„ç¬¦å·å’Œç©ºæ ¼
        position = re.sub(r'[^\u4e00-\u9fff\w\s]', ' ', position)
        position = re.sub(r'\s+', ' ', position).strip()
        
        return position if len(position) > 1 else ""

    def _extract_companies(self, text: str) -> List[str]:
        """æå–å…¬å¸ä¿¡æ¯"""
        companies = []
        
        # BOSSç›´è˜ç‰¹å®šçš„å…¬å¸æ ¼å¼
        patterns = [
            r'å…¬å¸åç§°[ï¼š:]\s*([^\n\r]+)',
            r'ä»»èŒå…¬å¸[ï¼š:]\s*([^\n\r]+)',
            r'å·¥ä½œå•ä½[ï¼š:]\s*([^\n\r]+)',
            # æ–°å¢ï¼šåŒ¹é…BOSSç›´è˜çš„å·¥ä½œç»å†æ ¼å¼
            r'([^\n\r]{3,30}(?:æœ‰é™å…¬å¸|è‚¡ä»½æœ‰é™å…¬å¸|é›†å›¢|ç§‘æŠ€|æŠ€æœ¯|ä¿¡æ¯|ç½‘ç»œ))[^\n\r]*\d{4}\.\d{2}[-â€”è‡³ä»Š\d\.]*',
            # åŒ¹é…æ—¶é—´å‰çš„å…¬å¸å
            r'([^\n\r]{3,30}(?:æœ‰é™å…¬å¸|è‚¡ä»½æœ‰é™å…¬å¸|é›†å›¢|ç§‘æŠ€|æŠ€æœ¯|ä¿¡æ¯|ç½‘ç»œ))[^\n\r]*(?=\s*\d{4}\.\d{2})',
        ]
        
        for pattern in patterns:
            matches = re.finditer(pattern, text)
            for match in matches:
                company = match.group(1).strip()
                company = self._clean_company_name(company)
                if company and company not in companies and company != 'ä¿å¯†':
                    companies.append(company)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡å‡†æ ¼å¼ï¼ŒæŸ¥æ‰¾æ—¶é—´æ®µ+å…¬å¸çš„æ¨¡å¼
        if not companies:
            # åŒ¹é…ï¼šæ—¶é—´æ®µ + å…¬å¸å
            work_pattern = r'(\d{4}\.\d{2}è‡³ä»Š|\d{4}\.\d{2}[-â€”è‡³]\d{4}\.\d{2})\s*([^\n\r\d]{3,30})'
            matches = re.finditer(work_pattern, text)
            for match in matches:
                company_text = match.group(2).strip()
                company = self._extract_company_from_text(company_text)
                if company and company not in companies and company != 'ä¿å¯†':
                    companies.append(company)
        
        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼ŒæŸ¥æ‰¾åŒ…å«å…¬å¸åç¼€çš„æ–‡æœ¬
        if not companies:
            for suffix in self.company_suffixes:
                pattern = rf'([^\n\r]{{2,20}}{re.escape(suffix)})'
                matches = re.finditer(pattern, text)
                for match in matches:
                    company = match.group(1).strip()
                    company = self._clean_company_name(company)
                    if company and len(company) < 30 and company not in companies and company != 'ä¿å¯†':
                        companies.append(company)
        
        return companies[:3]  # æœ€å¤šè¿”å›3ä¸ªå…¬å¸

    def _extract_company_from_text(self, text: str) -> str:
        """ä»æ–‡æœ¬ä¸­æå–å…¬å¸å"""
        # ç§»é™¤èŒä½ä¿¡æ¯
        for keyword in self.position_keywords:
            text = text.replace(keyword, '')
            
        # æŸ¥æ‰¾å…¬å¸åç¼€
        for suffix in self.company_suffixes:
            if suffix in text:
                # æå–åŒ…å«åç¼€çš„å…¬å¸å
                pattern = rf'([^\s\n]{{2,15}}{re.escape(suffix)})'
                match = re.search(pattern, text)
                if match:
                    return self._clean_company_name(match.group(1))
                    
        # å¦‚æœæ²¡æœ‰åç¼€ï¼Œè¿”å›æ¸…ç†åçš„æ–‡æœ¬
        return self._clean_company_name(text)

    def _clean_company_name(self, company: str) -> str:
        """æ¸…ç†å…¬å¸åç§°"""
        if not company:
            return ""
            
        # ç§»é™¤æ—¶é—´ä¿¡æ¯
        company = re.sub(r'\d{4}\.\d{2}[-â€”è‡³ä»Š\d\.]*', '', company)
        # ç§»é™¤èŒä½ä¿¡æ¯
        for keyword in self.position_keywords:
            company = company.replace(keyword, '')
        # æ¸…ç†ç¬¦å·
        company = re.sub(r'[^\u4e00-\u9fff\w\s]', ' ', company)
        company = re.sub(r'\s+', ' ', company).strip()
        
        return company if len(company) > 1 else ""

    def _extract_schools(self, text: str) -> List[str]:
        """æå–å­¦æ ¡ä¿¡æ¯"""
        schools = []
        
        # BOSSç›´è˜ç‰¹å®šçš„å­¦æ ¡æ ¼å¼
        patterns = [
            r'å­¦æ ¡åç§°[ï¼š:]\s*([^\n\r]+)',
            r'æ¯•ä¸šé™¢æ ¡[ï¼š:]\s*([^\n\r]+)',
            r'å°±è¯»å­¦æ ¡[ï¼š:]\s*([^\n\r]+)',
            # æ–°å¢ï¼šåŒ¹é…BOSSç›´è˜çš„æ•™è‚²ç»å†æ ¼å¼
            r'([^\n\r]{3,15}(?:å¤§å­¦|å­¦é™¢|å­¦æ ¡|èŒä¸šæŠ€æœ¯å­¦é™¢|å¸ˆèŒƒ))[^\n\r]*å·¥å•†ç®¡ç†',
            r'([^\n\r]{3,15}(?:å¤§å­¦|å­¦é™¢|å­¦æ ¡|èŒä¸šæŠ€æœ¯å­¦é™¢|å¸ˆèŒƒ))[^\n\r]*æœ¬ç§‘',
            r'([^\n\r]{3,15}(?:å¤§å­¦|å­¦é™¢|å­¦æ ¡|èŒä¸šæŠ€æœ¯å­¦é™¢|å¸ˆèŒƒ))[^\n\r]*ç¡•å£«',
            r'([^\n\r]{3,15}(?:å¤§å­¦|å­¦é™¢|å­¦æ ¡|èŒä¸šæŠ€æœ¯å­¦é™¢|å¸ˆèŒƒ))[^\n\r]*\d{4}[-â€”\d]*',
        ]
        
        for pattern in patterns:
            matches = re.finditer(pattern, text)
            for match in matches:
                school = match.group(1).strip()
                school = self._clean_school_name(school)
                if school and school not in schools:
                    schools.append(school)
        
        # æŸ¥æ‰¾åŒ…å«"å¤§å­¦"ã€"å­¦é™¢"ç­‰å…³é”®è¯çš„æ–‡æœ¬
        if not schools:
            school_keywords = ['å¤§å­¦', 'å­¦é™¢', 'å­¦æ ¡', 'èŒä¸šæŠ€æœ¯å­¦é™¢', 'å¸ˆèŒƒ']
            for keyword in school_keywords:
                pattern = rf'([^\n\r]{{2,15}}{re.escape(keyword)})'
                matches = re.finditer(pattern, text)
                for match in matches:
                    school = match.group(1).strip()
                    school = self._clean_school_name(school)
                    if school and len(school) < 20 and school not in schools:
                        schools.append(school)
        
        return schools[:2]  # æœ€å¤šè¿”å›2ä¸ªå­¦æ ¡

    def _clean_school_name(self, school: str) -> str:
        """æ¸…ç†å­¦æ ¡åç§°"""
        if not school:
            return ""
            
        # ç§»é™¤æ—¶é—´å’Œä¸“ä¸šä¿¡æ¯
        school = re.sub(r'\d{4}[-â€”è‡³ä»Š\d]*', '', school)
        school = re.sub(r'ä¸“ä¸š[ï¼š:].*', '', school)
        school = re.sub(r'è‹±è¯­.*', '', school)  # ç§»é™¤ä¸“ä¸šä¿¡æ¯
        school = re.sub(r'æœ¬ç§‘.*', '', school)  # ç§»é™¤å­¦å†ä¿¡æ¯
        school = re.sub(r'ç¡•å£«.*', '', school)  # ç§»é™¤å­¦å†ä¿¡æ¯
        # æ¸…ç†ç¬¦å·
        school = re.sub(r'[^\u4e00-\u9fff\w\s]', ' ', school)
        school = re.sub(r'\s+', ' ', school).strip()
        
        return school if len(school) > 1 else ""

    def _extract_skills(self, text: str) -> List[str]:
        """æå–æŠ€èƒ½"""
        skills = []
        
        # ä»æŠ€èƒ½æ ‡ç­¾éƒ¨åˆ†æå–
        skills_section_match = re.search(r'æŠ€èƒ½æ ‡ç­¾[ï¼š:](.*?)(?=\n\s*\n|\Z)', text, re.DOTALL)
        if skills_section_match:
            skills_text = skills_section_match.group(1)
            skill_candidates = re.split(r'[,ï¼Œã€\s]+', skills_text)
            for skill in skill_candidates:
                skill = skill.strip()
                if skill and len(skill) < 20 and skill not in skills:
                    skills.append(skill)
        
        # ä»æŠ€èƒ½å…³é”®è¯åº“ä¸­åŒ¹é…
        if len(skills) < 5:  # å¦‚æœæŠ€èƒ½å¤ªå°‘ï¼Œä»å…³é”®è¯åº“è¡¥å……
            for category, keywords in self.skill_keywords.items():
                for keyword in keywords:
                    if re.search(r'\b' + re.escape(keyword) + r'\b', text, re.IGNORECASE):
                        if keyword not in skills:
                            skills.append(keyword)
        
        return skills[:10]  # æœ€å¤šè¿”å›10ä¸ªæŠ€èƒ½

    def _extract_experience(self, text: str) -> int:
        """æå–å·¥ä½œç»éªŒå¹´é™"""
        patterns = [
            r'(\d+)[å¹´]ç»éªŒ',
            r'å·¥ä½œç»éªŒ[ï¼š:]\s*(\d+)[å¹´]',
            r'(\d+)[å¹´]å·¥ä½œç»éªŒ',
            r'(\d+)å¹´\+è¡Œä¸šç»éªŒ',  
            r'(\d+)\+å¹´ç»éªŒ',      
            r'(\d+)å¹´ è¡Œä¸šç»éªŒ',   
            # æ–°å¢ï¼šåŒ¹é…BOSSç›´è˜çš„å²—ä½ç»éªŒæ ¼å¼
            r'åª’ä»‹æŠ•æ”¾\s*(\d+)å¹´\d*ä¸ªæœˆ',
            r'SEM\s*(\d+)å¹´\d*ä¸ªæœˆ',
            r'æµ·å¤–å¸‚åœº\s*(\d+)å¹´\d*ä¸ªæœˆ',
            r'(\d+)å¹´\d*ä¸ªæœˆ',  # é€šç”¨æ ¼å¼
        ]
        
        max_years = 0
        for pattern in patterns:
            matches = re.finditer(pattern, text)
            for match in matches:
                years = int(match.group(1))
                if 0 <= years <= 50:  # åˆç†çš„å¹´é™èŒƒå›´
                    max_years = max(max_years, years)
                    
        return max_years

    def _extract_phone(self, text: str) -> str:
        """æå–ç”µè¯å·ç """
        pattern = r'1[3-9]\d{9}'
        match = re.search(pattern, text)
        return match.group(0) if match else ""

    def _extract_email(self, text: str) -> str:
        """æå–é‚®ç®±"""
        pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
        match = re.search(pattern, text)
        return match.group(0) if match else ""

    def _extract_salary_expectation(self, text: str) -> str:
        """æå–æœŸæœ›è–ªèµ„"""
        patterns = [
            r'(\d+-\d+K)',                    # 20-25Kæ ¼å¼
            r'(\d+K-\d+K)',                   # 20K-25Kæ ¼å¼
            r'(\d+k-\d+k)',                   # å°å†™kæ ¼å¼
            r'æœŸæœ›è–ªèµ„[ï¼š:]\s*([^\n\r]+)',     # æœŸæœ›è–ªèµ„æ ‡ç­¾
            r'è–ªèµ„è¦æ±‚[ï¼š:]\s*([^\n\r]+)',     # è–ªèµ„è¦æ±‚æ ‡ç­¾
            r'é¢è®®',                          # é¢è®®
            r'(\d+)-(\d+)ä¸‡',                 # ä¸‡å…ƒæ ¼å¼
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                salary = match.group(1) if match.groups() else match.group(0)
                return salary.strip()
                
        return ""

    def _extract_work_location(self, text: str) -> str:
        """æå–å·¥ä½œåœ°ç‚¹"""
        # å¸¸è§åŸå¸‚åˆ—è¡¨
        cities = [
            'åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³', 'æ­å·', 'å—äº¬', 'è‹å·', 'æˆéƒ½',
            'æ­¦æ±‰', 'è¥¿å®‰', 'å¤©æ´¥', 'é‡åº†', 'é’å²›', 'å¤§è¿', 'å¦é—¨', 'å®æ³¢',
            'æ— é”¡', 'ç¦å·', 'æµå—', 'éƒ‘å·', 'é•¿æ²™', 'çŸ³å®¶åº„', 'åˆè‚¥', 'ä¸œè'
        ]
        
        patterns = [
            r'æœŸæœ›.*?[ï¼š:]\s*([^ï¼Œ,\n\r]*(?:' + '|'.join(cities) + ')[^ï¼Œ,\n\r]*)',
            r'å·¥ä½œåœ°ç‚¹[ï¼š:]\s*([^\n\r]+)',
            r'([åŒ—ä¸Šå¹¿æ·±æ­].*?)[ï¼Œ,Â·\s]',  # ç®€ç§°åŒ¹é…
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                location = match.group(1).strip()
                # æ¸…ç†ä½ç½®ä¿¡æ¯
                for city in cities:
                    if city in location:
                        return city
                        
        return ""

    def _extract_position_experience(self, text: str) -> Dict[str, str]:
        """æå–å²—ä½ç»éªŒ"""
        position_exp = {}
        
        # åŒ¹é…å²—ä½ç»éªŒæ ¼å¼ï¼šå²—ä½å Xå¹´Yä¸ªæœˆ
        patterns = [
            r'([^\n\r]{2,20})\s*(\d+å¹´\d*ä¸ªæœˆ)',
            r'([^\n\r]{2,20})\s*(\d+å¹´)',
            r'([^\n\r]{2,20})\s*(\d+ä¸ªæœˆ)',
        ]
        
        for pattern in patterns:
            matches = re.finditer(pattern, text)
            for match in matches:
                position = match.group(1).strip()
                experience = match.group(2).strip()
                # æ¸…ç†èŒä½åç§°
                position = re.sub(r'[^\u4e00-\u9fff\w\s]', ' ', position).strip()
                if len(position) > 1 and len(position) < 20:
                    position_exp[position] = experience
        
        return position_exp

    async def merge_resume_data(self, card_data: Dict, detail_data: Dict) -> Dict:
        """
        åˆå¹¶å¡ç‰‡æ•°æ®å’Œè¯¦æƒ…é¡µæ•°æ®
        
        Args:
            card_data: å¡ç‰‡æ•°æ®
            detail_data: è¯¦æƒ…é¡µæ•°æ®
            
        Returns:
            dict: åˆå¹¶åçš„æ•°æ®
        """
        merged_data = card_data.copy() if card_data else {}
        
        if not detail_data:
            return merged_data
            
        # æ™ºèƒ½åˆå¹¶ç­–ç•¥
        for key, value in detail_data.items():
            if not value:  # è·³è¿‡ç©ºå€¼
                continue
                
            if key in ['company', 'schools', 'skills'] and isinstance(value, list):
                # åˆ—è¡¨ç±»å‹æ•°æ®åˆå¹¶å»é‡
                existing = merged_data.get(key, [])
                if isinstance(existing, list):
                    merged_data[key] = list(set(existing + value))
                else:
                    merged_data[key] = value
            elif key in ['name', 'education', 'position'] and value:
                # é‡è¦å­—æ®µä¼˜å…ˆä½¿ç”¨è¯¦æƒ…é¡µæ•°æ®
                merged_data[key] = value
            elif not merged_data.get(key):
                # å¦‚æœåŸæ•°æ®æ²¡æœ‰è¯¥å­—æ®µï¼Œä½¿ç”¨è¯¦æƒ…é¡µæ•°æ®
                merged_data[key] = value
                
        return merged_data 